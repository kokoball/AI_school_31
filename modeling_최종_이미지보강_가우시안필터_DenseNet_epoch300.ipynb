{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "# 이미지 처리 \n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from random import shuffle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob as gb\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './Data' # 기본경로\n",
    "train_dir = os.path.join(base_dir, 'train') # 학습 데이터 경로\n",
    "test_dir = os.path.join(base_dir, 'test') # 테스트 데이더 경로\n",
    "p_train_dir = os.path.join(base_dir, 'p_train') # 추가학습 데이터 경로  # 으로 다 합침\n",
    "p_test_dir = os.path.join(base_dir, 'p_test') # 추가학습 데이터 경로  # 으로 다 합침\n",
    "\n",
    "\n",
    "# 학습 사진\n",
    "train_covid_dir = os.path.join(train_dir, 'COVID19')\n",
    "train_normal_dir = os.path.join(train_dir, 'NORMAL')\n",
    "train_pneum_dir = os.path.join(train_dir, 'PNEUMONIA')\n",
    "\n",
    "# 추가 학습 사진\n",
    "p_train_covid_dir = os.path.join(p_train_dir, 'COVID19')\n",
    "p_train_normal_dir = os.path.join(p_train_dir, 'NORMAL')\n",
    "p_train_pneum_dir = os.path.join(p_train_dir, 'PNEUMONIA')\n",
    "\n",
    "# 테스트  사진\n",
    "test_covid_dir = os.path.join(test_dir, 'COVID19')\n",
    "test_normal_dir = os.path.join(test_dir, 'NORMAL')\n",
    "test_pneum_dir = os.path.join(test_dir, 'PNEUMONIA')\n",
    "\n",
    "# 추가 테스트 사진\n",
    "\n",
    "p_test_covid_dir = os.path.join(p_test_dir, 'COVID19')\n",
    "p_test_normal_dir = os.path.join(p_test_dir, 'NORMAL')\n",
    "p_test_pneum_dir = os.path.join(p_test_dir, 'PNEUMONIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COVID19(0).jpg', 'COVID19(1).jpg', 'COVID19(10).jpg', 'COVID19(101).jpg', 'COVID19(102).jpg', 'COVID19(103).jpg', 'COVID19(104).jpg', 'COVID19(105).jpg', 'COVID19(107).jpg', 'COVID19(108).jpg']\n",
      "['NORMAL(0).jpg', 'NORMAL(1).jpg', 'NORMAL(100).jpg', 'NORMAL(1000).jpg', 'NORMAL(1002).jpg', 'NORMAL(1005).jpg', 'NORMAL(1006).jpg', 'NORMAL(1007).jpg', 'NORMAL(1008).jpg', 'NORMAL(1009).jpg']\n",
      "['NORMAL(0).jpg', 'NORMAL(1).jpg', 'NORMAL(100).jpg', 'NORMAL(1000).jpg', 'NORMAL(1002).jpg', 'NORMAL(1005).jpg', 'NORMAL(1006).jpg', 'NORMAL(1007).jpg', 'NORMAL(1008).jpg', 'NORMAL(1009).jpg']\n"
     ]
    }
   ],
   "source": [
    "# 제대로 경로 지정 됐는지 확인\n",
    "train_covid_fname = os.listdir(train_covid_dir)\n",
    "train_normal_fname = os.listdir(train_normal_dir)\n",
    "train_pneum_fname = os.listdir(train_pneum_dir)\n",
    "\n",
    "test_covid_fname = os.listdir(test_covid_dir)\n",
    "test_normal_fname = os.listdir(test_normal_dir)\n",
    "test_pneum_fname = os.listdir(test_pneum_dir)\n",
    "\n",
    "p_train_covid_fname = os.listdir(p_train_covid_dir)\n",
    "p_train_normal_fname = os.listdir(p_train_normal_dir)\n",
    "p_train_pneum_fname = os.listdir(p_train_pneum_dir)\n",
    "\n",
    "p_test_covid_fname = os.listdir(p_test_covid_dir)\n",
    "p_test_normal_fname = os.listdir(p_test_normal_dir)\n",
    "p_test_pneum_fname = os.listdir(p_test_pneum_dir)\n",
    "\n",
    "print(train_covid_fname[:10]) # 열개만 확인\n",
    "print(train_normal_fname[:10])\n",
    "print(p_train_normal_fname[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 학습용 코로나 이미지 개수는:  460\n",
      "전체 학습용 정상 이미지 개수는:  1266\n",
      "전체 학습용 폐렴 이미지 개수는:  3418\n",
      "-----------------------------------------------------\n",
      "전체 테스트용 코로나 이미지 개수는:  116\n",
      "전체 테스트용 정상 이미지 개수는:  317\n",
      "전체 테스트용 폐렴 이미지 개수는:  855\n",
      "-----------------------------------------------------\n",
      "전체 추가 학습용 코로나 이미지 개수는:  6857\n",
      "전체 추가 학습용 정상 이미지 개수는:  7644\n",
      "전체 추가 학습용 폐렴 이미지 개수는:  9788\n",
      "-----------------------------------------------------\n",
      "전체 추가 테스트용 코로나 이미지 개수는:  2423\n",
      "전체 추가 테스트용 정상 이미지 개수는:  2565\n",
      "전체 추가 테스트용 폐렴 이미지 개수는:  3099\n"
     ]
    }
   ],
   "source": [
    "# train 및 test 디렉토리에서 코로나, 정상, 폐렴의 이미지 총 수를 알아보기\n",
    "print(\"전체 학습용 코로나 이미지 개수는: \", len(os.listdir(train_covid_dir)))\n",
    "print(\"전체 학습용 정상 이미지 개수는: \", len(os.listdir(train_normal_dir)))\n",
    "print(\"전체 학습용 폐렴 이미지 개수는: \", len(os.listdir(train_pneum_dir)))\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "print(\"전체 테스트용 코로나 이미지 개수는: \", len(os.listdir(test_covid_dir)))\n",
    "print(\"전체 테스트용 정상 이미지 개수는: \", len(os.listdir(test_normal_dir)))\n",
    "print(\"전체 테스트용 폐렴 이미지 개수는: \", len(os.listdir(test_pneum_dir)))\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"전체 추가 학습용 코로나 이미지 개수는: \", len(os.listdir(p_train_covid_dir)))\n",
    "print(\"전체 추가 학습용 정상 이미지 개수는: \", len(os.listdir(p_train_normal_dir)))\n",
    "print(\"전체 추가 학습용 폐렴 이미지 개수는: \", len(os.listdir(p_train_pneum_dir)))\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "print(\"전체 추가 테스트용 코로나 이미지 개수는: \", len(os.listdir(p_test_covid_dir)))\n",
    "print(\"전체 추가 테스트용 정상 이미지 개수는: \", len(os.listdir(p_test_normal_dir)))\n",
    "print(\"전체 추가 테스트용 폐렴 이미지 개수는: \", len(os.listdir(p_test_pneum_dir)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "PNEUMONIA\n"
     ]
    }
   ],
   "source": [
    "Labels = {'NORMAL':0,'PNEUMONIA':1,'COVID19':2}\n",
    "\n",
    "def getCode(label):\n",
    "    return Labels[label]\n",
    "\n",
    "def getLabel(n):\n",
    "    for x,c in Labels.items():\n",
    "        if n==c:\n",
    "            return x\n",
    "        \n",
    "print(getCode('COVID19'))\n",
    "print(getLabel(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as gb\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "sizeImage = 224\n",
    "\n",
    "def train_getData(Dir,sizeImage):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for folder in os.listdir(Dir) :\n",
    "        files = gb.glob(pathname = str(Dir + '/' + folder + '//*.jpg'))\n",
    "        random.shuffle(files)\n",
    "        for num in range(5000) :\n",
    "            picture = cv2.imread(files[num])\n",
    "            imageArray = cv2.resize(picture,(sizeImage,sizeImage))\n",
    "            img = cv2.GaussianBlur(imageArray,(5,5),0)\n",
    "            X.append(list(img))\n",
    "            y.append(getCode(folder))\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "def test_getData(Dir,sizeImage):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for folder in os.listdir(Dir) :\n",
    "        files = gb.glob(pathname = str(Dir + '/' + folder + '//*.jpg'))\n",
    "        random.shuffle(files)\n",
    "        for num in range(1250) :\n",
    "            picture = cv2.imread(files[num])\n",
    "            imageArray = cv2.resize(picture,(sizeImage,sizeImage))\n",
    "            img = cv2.GaussianBlur(imageArray,(5,5),0)\n",
    "            X.append(list(img))\n",
    "            y.append(getCode(folder))\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_getData(p_train_dir,sizeImage)\n",
    "X_test,y_test = test_getData(p_test_dir,sizeImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 셔플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train = [[x,y] for x, y in zip(X_train, y_train)]\n",
    "tmp_test = [[x,y] for x, y in zip(X_test, y_test)]\n",
    "\n",
    "import random\n",
    "random.shuffle(tmp_train)\n",
    "random.shuffle(tmp_test)\n",
    "\n",
    "X_train = [n[0] for n in tmp_train]\n",
    "y_train = [n[1] for n in tmp_train]\n",
    "\n",
    "X_test = [n[0] for n in tmp_test]\n",
    "y_test = [n[1] for n in tmp_test]\n",
    "\n",
    "# 리스트에서 배열로\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape :  (15000, 224, 224, 3)\n",
      "X_test Shape :  (3750, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Shape : \",X_train.shape)\n",
    "print(\"X_test Shape : \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4eba1a477f91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet201\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 14, 14, 1024) 0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 14, 14, 128)  131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 14, 14, 1056) 0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 14, 14, 1056) 4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 14, 14, 1056) 0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 14, 14, 128)  135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 14, 14, 1088) 0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 14, 14, 1088) 4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 14, 14, 1088) 0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 14, 14, 128)  139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 14, 14, 1120) 0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 14, 14, 1120) 4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 14, 14, 1120) 0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 14, 14, 128)  143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 14, 14, 1152) 0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 14, 14, 1152) 4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 14, 14, 1152) 0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 14, 14, 128)  147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 14, 14, 1184) 0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 14, 14, 1184) 4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 14, 14, 1184) 0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 14, 14, 128)  151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 14, 14, 1216) 0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 14, 14, 1216) 4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 14, 14, 1216) 0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 14, 14, 128)  155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 14, 14, 1248) 0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 14, 14, 1248) 4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 14, 14, 1248) 0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 14, 14, 128)  159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_concat (Concatena (None, 14, 14, 1280) 0           conv4_block31_concat[0][0]       \n",
      "                                                                 conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_0_bn (BatchNormal (None, 14, 14, 1280) 5120        conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_0_relu (Activatio (None, 14, 14, 1280) 0           conv4_block33_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_conv (Conv2D)   (None, 14, 14, 128)  163840      conv4_block33_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block33_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block33_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block33_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_concat (Concatena (None, 14, 14, 1312) 0           conv4_block32_concat[0][0]       \n",
      "                                                                 conv4_block33_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_0_bn (BatchNormal (None, 14, 14, 1312) 5248        conv4_block33_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_0_relu (Activatio (None, 14, 14, 1312) 0           conv4_block34_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_conv (Conv2D)   (None, 14, 14, 128)  167936      conv4_block34_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block34_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block34_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block34_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_concat (Concatena (None, 14, 14, 1344) 0           conv4_block33_concat[0][0]       \n",
      "                                                                 conv4_block34_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_0_bn (BatchNormal (None, 14, 14, 1344) 5376        conv4_block34_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_0_relu (Activatio (None, 14, 14, 1344) 0           conv4_block35_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_conv (Conv2D)   (None, 14, 14, 128)  172032      conv4_block35_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block35_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block35_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block35_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_concat (Concatena (None, 14, 14, 1376) 0           conv4_block34_concat[0][0]       \n",
      "                                                                 conv4_block35_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_0_bn (BatchNormal (None, 14, 14, 1376) 5504        conv4_block35_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_0_relu (Activatio (None, 14, 14, 1376) 0           conv4_block36_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_conv (Conv2D)   (None, 14, 14, 128)  176128      conv4_block36_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block36_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block36_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block36_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_concat (Concatena (None, 14, 14, 1408) 0           conv4_block35_concat[0][0]       \n",
      "                                                                 conv4_block36_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_0_bn (BatchNormal (None, 14, 14, 1408) 5632        conv4_block36_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_0_relu (Activatio (None, 14, 14, 1408) 0           conv4_block37_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_1_conv (Conv2D)   (None, 14, 14, 128)  180224      conv4_block37_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block37_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block37_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block37_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_concat (Concatena (None, 14, 14, 1440) 0           conv4_block36_concat[0][0]       \n",
      "                                                                 conv4_block37_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_0_bn (BatchNormal (None, 14, 14, 1440) 5760        conv4_block37_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_0_relu (Activatio (None, 14, 14, 1440) 0           conv4_block38_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_1_conv (Conv2D)   (None, 14, 14, 128)  184320      conv4_block38_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block38_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block38_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block38_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_concat (Concatena (None, 14, 14, 1472) 0           conv4_block37_concat[0][0]       \n",
      "                                                                 conv4_block38_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_0_bn (BatchNormal (None, 14, 14, 1472) 5888        conv4_block38_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_0_relu (Activatio (None, 14, 14, 1472) 0           conv4_block39_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_1_conv (Conv2D)   (None, 14, 14, 128)  188416      conv4_block39_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block39_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block39_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block39_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_concat (Concatena (None, 14, 14, 1504) 0           conv4_block38_concat[0][0]       \n",
      "                                                                 conv4_block39_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_0_bn (BatchNormal (None, 14, 14, 1504) 6016        conv4_block39_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_0_relu (Activatio (None, 14, 14, 1504) 0           conv4_block40_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_1_conv (Conv2D)   (None, 14, 14, 128)  192512      conv4_block40_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block40_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block40_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block40_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_concat (Concatena (None, 14, 14, 1536) 0           conv4_block39_concat[0][0]       \n",
      "                                                                 conv4_block40_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_0_bn (BatchNormal (None, 14, 14, 1536) 6144        conv4_block40_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_0_relu (Activatio (None, 14, 14, 1536) 0           conv4_block41_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_1_conv (Conv2D)   (None, 14, 14, 128)  196608      conv4_block41_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block41_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block41_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block41_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_concat (Concatena (None, 14, 14, 1568) 0           conv4_block40_concat[0][0]       \n",
      "                                                                 conv4_block41_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_0_bn (BatchNormal (None, 14, 14, 1568) 6272        conv4_block41_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_0_relu (Activatio (None, 14, 14, 1568) 0           conv4_block42_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_1_conv (Conv2D)   (None, 14, 14, 128)  200704      conv4_block42_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block42_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block42_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block42_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_concat (Concatena (None, 14, 14, 1600) 0           conv4_block41_concat[0][0]       \n",
      "                                                                 conv4_block42_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_0_bn (BatchNormal (None, 14, 14, 1600) 6400        conv4_block42_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_0_relu (Activatio (None, 14, 14, 1600) 0           conv4_block43_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_1_conv (Conv2D)   (None, 14, 14, 128)  204800      conv4_block43_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block43_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block43_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block43_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_concat (Concatena (None, 14, 14, 1632) 0           conv4_block42_concat[0][0]       \n",
      "                                                                 conv4_block43_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_0_bn (BatchNormal (None, 14, 14, 1632) 6528        conv4_block43_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_0_relu (Activatio (None, 14, 14, 1632) 0           conv4_block44_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_1_conv (Conv2D)   (None, 14, 14, 128)  208896      conv4_block44_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block44_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block44_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block44_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_concat (Concatena (None, 14, 14, 1664) 0           conv4_block43_concat[0][0]       \n",
      "                                                                 conv4_block44_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_0_bn (BatchNormal (None, 14, 14, 1664) 6656        conv4_block44_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_0_relu (Activatio (None, 14, 14, 1664) 0           conv4_block45_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_1_conv (Conv2D)   (None, 14, 14, 128)  212992      conv4_block45_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block45_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block45_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block45_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_concat (Concatena (None, 14, 14, 1696) 0           conv4_block44_concat[0][0]       \n",
      "                                                                 conv4_block45_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_0_bn (BatchNormal (None, 14, 14, 1696) 6784        conv4_block45_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_0_relu (Activatio (None, 14, 14, 1696) 0           conv4_block46_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_1_conv (Conv2D)   (None, 14, 14, 128)  217088      conv4_block46_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block46_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block46_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block46_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_concat (Concatena (None, 14, 14, 1728) 0           conv4_block45_concat[0][0]       \n",
      "                                                                 conv4_block46_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_0_bn (BatchNormal (None, 14, 14, 1728) 6912        conv4_block46_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_0_relu (Activatio (None, 14, 14, 1728) 0           conv4_block47_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_1_conv (Conv2D)   (None, 14, 14, 128)  221184      conv4_block47_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block47_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block47_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block47_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_concat (Concatena (None, 14, 14, 1760) 0           conv4_block46_concat[0][0]       \n",
      "                                                                 conv4_block47_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_0_bn (BatchNormal (None, 14, 14, 1760) 7040        conv4_block47_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_0_relu (Activatio (None, 14, 14, 1760) 0           conv4_block48_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_1_conv (Conv2D)   (None, 14, 14, 128)  225280      conv4_block48_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block48_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block48_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block48_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_concat (Concatena (None, 14, 14, 1792) 0           conv4_block47_concat[0][0]       \n",
      "                                                                 conv4_block48_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1792) 7168        conv4_block48_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1792) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 896)  1605632     pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 896)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 896)    3584        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 896)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    114688      conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 928)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 928)    3712        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 928)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    118784      conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 960)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 960)    3840        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 960)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    122880      conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 992)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 992)    3968        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 992)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    126976      conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 1024)   0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 1024)   4096        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 1024)   0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    131072      conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 1056)   0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 1056)   4224        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 1056)   0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    135168      conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 1088)   0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 1088)   4352        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 1088)   0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    139264      conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 1120)   0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 1120)   4480        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 1120)   0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    143360      conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 1152)   0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 1152)   4608        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 1152)   0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    147456      conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 1184)   0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 1184)   4736        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 1184)   0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    151552      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 1216)   0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 1216)   4864        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 1216)   0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    155648      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 1248)   0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 1248)   4992        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 1248)   0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    159744      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 1280)   0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 1280)   5120        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 1280)   0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    163840      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 1312)   0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 1312)   5248        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 1312)   0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    167936      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 1344)   0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 1344)   5376        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 1344)   0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    172032      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 1376)   0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 1376)   5504        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 1376)   0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    176128      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1408)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_bn (BatchNormal (None, 7, 7, 1408)   5632        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_relu (Activatio (None, 7, 7, 1408)   0           conv5_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_conv (Conv2D)   (None, 7, 7, 128)    180224      conv5_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_concat (Concatena (None, 7, 7, 1440)   0           conv5_block16_concat[0][0]       \n",
      "                                                                 conv5_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_bn (BatchNormal (None, 7, 7, 1440)   5760        conv5_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_relu (Activatio (None, 7, 7, 1440)   0           conv5_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_conv (Conv2D)   (None, 7, 7, 128)    184320      conv5_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_concat (Concatena (None, 7, 7, 1472)   0           conv5_block17_concat[0][0]       \n",
      "                                                                 conv5_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_bn (BatchNormal (None, 7, 7, 1472)   5888        conv5_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_relu (Activatio (None, 7, 7, 1472)   0           conv5_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_conv (Conv2D)   (None, 7, 7, 128)    188416      conv5_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_concat (Concatena (None, 7, 7, 1504)   0           conv5_block18_concat[0][0]       \n",
      "                                                                 conv5_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_bn (BatchNormal (None, 7, 7, 1504)   6016        conv5_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_relu (Activatio (None, 7, 7, 1504)   0           conv5_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_conv (Conv2D)   (None, 7, 7, 128)    192512      conv5_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_concat (Concatena (None, 7, 7, 1536)   0           conv5_block19_concat[0][0]       \n",
      "                                                                 conv5_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_bn (BatchNormal (None, 7, 7, 1536)   6144        conv5_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_relu (Activatio (None, 7, 7, 1536)   0           conv5_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_conv (Conv2D)   (None, 7, 7, 128)    196608      conv5_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_concat (Concatena (None, 7, 7, 1568)   0           conv5_block20_concat[0][0]       \n",
      "                                                                 conv5_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_bn (BatchNormal (None, 7, 7, 1568)   6272        conv5_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_relu (Activatio (None, 7, 7, 1568)   0           conv5_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_conv (Conv2D)   (None, 7, 7, 128)    200704      conv5_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_concat (Concatena (None, 7, 7, 1600)   0           conv5_block21_concat[0][0]       \n",
      "                                                                 conv5_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_bn (BatchNormal (None, 7, 7, 1600)   6400        conv5_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_relu (Activatio (None, 7, 7, 1600)   0           conv5_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_conv (Conv2D)   (None, 7, 7, 128)    204800      conv5_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_concat (Concatena (None, 7, 7, 1632)   0           conv5_block22_concat[0][0]       \n",
      "                                                                 conv5_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_bn (BatchNormal (None, 7, 7, 1632)   6528        conv5_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_relu (Activatio (None, 7, 7, 1632)   0           conv5_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_conv (Conv2D)   (None, 7, 7, 128)    208896      conv5_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_concat (Concatena (None, 7, 7, 1664)   0           conv5_block23_concat[0][0]       \n",
      "                                                                 conv5_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_bn (BatchNormal (None, 7, 7, 1664)   6656        conv5_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_relu (Activatio (None, 7, 7, 1664)   0           conv5_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_conv (Conv2D)   (None, 7, 7, 128)    212992      conv5_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_concat (Concatena (None, 7, 7, 1696)   0           conv5_block24_concat[0][0]       \n",
      "                                                                 conv5_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_bn (BatchNormal (None, 7, 7, 1696)   6784        conv5_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_relu (Activatio (None, 7, 7, 1696)   0           conv5_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_conv (Conv2D)   (None, 7, 7, 128)    217088      conv5_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_concat (Concatena (None, 7, 7, 1728)   0           conv5_block25_concat[0][0]       \n",
      "                                                                 conv5_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_bn (BatchNormal (None, 7, 7, 1728)   6912        conv5_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_relu (Activatio (None, 7, 7, 1728)   0           conv5_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_conv (Conv2D)   (None, 7, 7, 128)    221184      conv5_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_concat (Concatena (None, 7, 7, 1760)   0           conv5_block26_concat[0][0]       \n",
      "                                                                 conv5_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_bn (BatchNormal (None, 7, 7, 1760)   7040        conv5_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_relu (Activatio (None, 7, 7, 1760)   0           conv5_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_conv (Conv2D)   (None, 7, 7, 128)    225280      conv5_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_concat (Concatena (None, 7, 7, 1792)   0           conv5_block27_concat[0][0]       \n",
      "                                                                 conv5_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_bn (BatchNormal (None, 7, 7, 1792)   7168        conv5_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_relu (Activatio (None, 7, 7, 1792)   0           conv5_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_conv (Conv2D)   (None, 7, 7, 128)    229376      conv5_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_concat (Concatena (None, 7, 7, 1824)   0           conv5_block28_concat[0][0]       \n",
      "                                                                 conv5_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_bn (BatchNormal (None, 7, 7, 1824)   7296        conv5_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_relu (Activatio (None, 7, 7, 1824)   0           conv5_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_conv (Conv2D)   (None, 7, 7, 128)    233472      conv5_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_concat (Concatena (None, 7, 7, 1856)   0           conv5_block29_concat[0][0]       \n",
      "                                                                 conv5_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_bn (BatchNormal (None, 7, 7, 1856)   7424        conv5_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_relu (Activatio (None, 7, 7, 1856)   0           conv5_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_conv (Conv2D)   (None, 7, 7, 128)    237568      conv5_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 7, 7, 1888)   0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 7, 7, 1888)   7552        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 7, 7, 1888)   0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 7, 7, 128)    241664      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 7, 7, 1920)   0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1920)   7680        conv5_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1920)   0           bn[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 18,321,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 18,321,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet201\n",
    "pre_trained_model = DenseNet201(input_shape = (sizeImage,sizeImage,3), include_top = False,  weights='imagenet')\n",
    "for layer in pre_trained_model.layers :\n",
    "    layer.trainable = False\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet_type\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 14, 14, 1024) 0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 14, 14, 128)  131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 14, 14, 1056) 0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 14, 14, 1056) 4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 14, 14, 1056) 0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 14, 14, 128)  135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 14, 14, 1088) 0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 14, 14, 1088) 4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 14, 14, 1088) 0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 14, 14, 128)  139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 14, 14, 1120) 0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 14, 14, 1120) 4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 14, 14, 1120) 0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 14, 14, 128)  143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 14, 14, 1152) 0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 14, 14, 1152) 4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 14, 14, 1152) 0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 14, 14, 128)  147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 14, 14, 1184) 0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 14, 14, 1184) 4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 14, 14, 1184) 0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 14, 14, 128)  151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 14, 14, 1216) 0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 14, 14, 1216) 4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 14, 14, 1216) 0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 14, 14, 128)  155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 14, 14, 1248) 0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 14, 14, 1248) 4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 14, 14, 1248) 0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 14, 14, 128)  159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_concat (Concatena (None, 14, 14, 1280) 0           conv4_block31_concat[0][0]       \n",
      "                                                                 conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_0_bn (BatchNormal (None, 14, 14, 1280) 5120        conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_0_relu (Activatio (None, 14, 14, 1280) 0           conv4_block33_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_conv (Conv2D)   (None, 14, 14, 128)  163840      conv4_block33_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block33_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block33_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block33_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_concat (Concatena (None, 14, 14, 1312) 0           conv4_block32_concat[0][0]       \n",
      "                                                                 conv4_block33_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_0_bn (BatchNormal (None, 14, 14, 1312) 5248        conv4_block33_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_0_relu (Activatio (None, 14, 14, 1312) 0           conv4_block34_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_conv (Conv2D)   (None, 14, 14, 128)  167936      conv4_block34_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block34_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block34_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block34_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_concat (Concatena (None, 14, 14, 1344) 0           conv4_block33_concat[0][0]       \n",
      "                                                                 conv4_block34_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_0_bn (BatchNormal (None, 14, 14, 1344) 5376        conv4_block34_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_0_relu (Activatio (None, 14, 14, 1344) 0           conv4_block35_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_conv (Conv2D)   (None, 14, 14, 128)  172032      conv4_block35_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block35_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block35_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block35_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_concat (Concatena (None, 14, 14, 1376) 0           conv4_block34_concat[0][0]       \n",
      "                                                                 conv4_block35_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_0_bn (BatchNormal (None, 14, 14, 1376) 5504        conv4_block35_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_0_relu (Activatio (None, 14, 14, 1376) 0           conv4_block36_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_conv (Conv2D)   (None, 14, 14, 128)  176128      conv4_block36_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block36_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block36_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block36_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_concat (Concatena (None, 14, 14, 1408) 0           conv4_block35_concat[0][0]       \n",
      "                                                                 conv4_block36_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_0_bn (BatchNormal (None, 14, 14, 1408) 5632        conv4_block36_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_0_relu (Activatio (None, 14, 14, 1408) 0           conv4_block37_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_1_conv (Conv2D)   (None, 14, 14, 128)  180224      conv4_block37_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block37_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block37_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block37_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_concat (Concatena (None, 14, 14, 1440) 0           conv4_block36_concat[0][0]       \n",
      "                                                                 conv4_block37_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_0_bn (BatchNormal (None, 14, 14, 1440) 5760        conv4_block37_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_0_relu (Activatio (None, 14, 14, 1440) 0           conv4_block38_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_1_conv (Conv2D)   (None, 14, 14, 128)  184320      conv4_block38_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block38_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block38_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block38_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_concat (Concatena (None, 14, 14, 1472) 0           conv4_block37_concat[0][0]       \n",
      "                                                                 conv4_block38_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_0_bn (BatchNormal (None, 14, 14, 1472) 5888        conv4_block38_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_0_relu (Activatio (None, 14, 14, 1472) 0           conv4_block39_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_1_conv (Conv2D)   (None, 14, 14, 128)  188416      conv4_block39_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block39_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block39_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block39_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_concat (Concatena (None, 14, 14, 1504) 0           conv4_block38_concat[0][0]       \n",
      "                                                                 conv4_block39_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_0_bn (BatchNormal (None, 14, 14, 1504) 6016        conv4_block39_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_0_relu (Activatio (None, 14, 14, 1504) 0           conv4_block40_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_1_conv (Conv2D)   (None, 14, 14, 128)  192512      conv4_block40_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block40_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block40_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block40_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_concat (Concatena (None, 14, 14, 1536) 0           conv4_block39_concat[0][0]       \n",
      "                                                                 conv4_block40_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_0_bn (BatchNormal (None, 14, 14, 1536) 6144        conv4_block40_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_0_relu (Activatio (None, 14, 14, 1536) 0           conv4_block41_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_1_conv (Conv2D)   (None, 14, 14, 128)  196608      conv4_block41_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block41_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block41_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block41_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_concat (Concatena (None, 14, 14, 1568) 0           conv4_block40_concat[0][0]       \n",
      "                                                                 conv4_block41_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_0_bn (BatchNormal (None, 14, 14, 1568) 6272        conv4_block41_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_0_relu (Activatio (None, 14, 14, 1568) 0           conv4_block42_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_1_conv (Conv2D)   (None, 14, 14, 128)  200704      conv4_block42_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block42_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block42_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block42_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_concat (Concatena (None, 14, 14, 1600) 0           conv4_block41_concat[0][0]       \n",
      "                                                                 conv4_block42_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_0_bn (BatchNormal (None, 14, 14, 1600) 6400        conv4_block42_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_0_relu (Activatio (None, 14, 14, 1600) 0           conv4_block43_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_1_conv (Conv2D)   (None, 14, 14, 128)  204800      conv4_block43_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block43_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block43_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block43_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_concat (Concatena (None, 14, 14, 1632) 0           conv4_block42_concat[0][0]       \n",
      "                                                                 conv4_block43_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_0_bn (BatchNormal (None, 14, 14, 1632) 6528        conv4_block43_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_0_relu (Activatio (None, 14, 14, 1632) 0           conv4_block44_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_1_conv (Conv2D)   (None, 14, 14, 128)  208896      conv4_block44_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block44_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block44_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block44_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_concat (Concatena (None, 14, 14, 1664) 0           conv4_block43_concat[0][0]       \n",
      "                                                                 conv4_block44_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_0_bn (BatchNormal (None, 14, 14, 1664) 6656        conv4_block44_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_0_relu (Activatio (None, 14, 14, 1664) 0           conv4_block45_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_1_conv (Conv2D)   (None, 14, 14, 128)  212992      conv4_block45_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block45_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block45_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block45_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_concat (Concatena (None, 14, 14, 1696) 0           conv4_block44_concat[0][0]       \n",
      "                                                                 conv4_block45_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_0_bn (BatchNormal (None, 14, 14, 1696) 6784        conv4_block45_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_0_relu (Activatio (None, 14, 14, 1696) 0           conv4_block46_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_1_conv (Conv2D)   (None, 14, 14, 128)  217088      conv4_block46_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block46_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block46_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block46_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_concat (Concatena (None, 14, 14, 1728) 0           conv4_block45_concat[0][0]       \n",
      "                                                                 conv4_block46_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_0_bn (BatchNormal (None, 14, 14, 1728) 6912        conv4_block46_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_0_relu (Activatio (None, 14, 14, 1728) 0           conv4_block47_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_1_conv (Conv2D)   (None, 14, 14, 128)  221184      conv4_block47_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block47_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block47_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block47_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_concat (Concatena (None, 14, 14, 1760) 0           conv4_block46_concat[0][0]       \n",
      "                                                                 conv4_block47_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_0_bn (BatchNormal (None, 14, 14, 1760) 7040        conv4_block47_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_0_relu (Activatio (None, 14, 14, 1760) 0           conv4_block48_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_1_conv (Conv2D)   (None, 14, 14, 128)  225280      conv4_block48_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block48_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block48_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block48_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_concat (Concatena (None, 14, 14, 1792) 0           conv4_block47_concat[0][0]       \n",
      "                                                                 conv4_block48_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1792) 7168        conv4_block48_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1792) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 896)  1605632     pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 896)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 896)    3584        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 896)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    114688      conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 928)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 928)    3712        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 928)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    118784      conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 960)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 960)    3840        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 960)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    122880      conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 992)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 992)    3968        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 992)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    126976      conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 1024)   0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 1024)   4096        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 1024)   0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    131072      conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 1056)   0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 1056)   4224        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 1056)   0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    135168      conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 1088)   0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 1088)   4352        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 1088)   0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    139264      conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 1120)   0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 1120)   4480        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 1120)   0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    143360      conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 1152)   0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 1152)   4608        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 1152)   0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    147456      conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 1184)   0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 1184)   4736        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 1184)   0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    151552      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 1216)   0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 1216)   4864        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 1216)   0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    155648      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 1248)   0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 1248)   4992        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 1248)   0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    159744      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 1280)   0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 1280)   5120        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 1280)   0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    163840      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 1312)   0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 1312)   5248        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 1312)   0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    167936      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 1344)   0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 1344)   5376        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 1344)   0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    172032      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 1376)   0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 1376)   5504        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 1376)   0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    176128      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1408)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_bn (BatchNormal (None, 7, 7, 1408)   5632        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_relu (Activatio (None, 7, 7, 1408)   0           conv5_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_conv (Conv2D)   (None, 7, 7, 128)    180224      conv5_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_concat (Concatena (None, 7, 7, 1440)   0           conv5_block16_concat[0][0]       \n",
      "                                                                 conv5_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_bn (BatchNormal (None, 7, 7, 1440)   5760        conv5_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_relu (Activatio (None, 7, 7, 1440)   0           conv5_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_conv (Conv2D)   (None, 7, 7, 128)    184320      conv5_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_concat (Concatena (None, 7, 7, 1472)   0           conv5_block17_concat[0][0]       \n",
      "                                                                 conv5_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_bn (BatchNormal (None, 7, 7, 1472)   5888        conv5_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_relu (Activatio (None, 7, 7, 1472)   0           conv5_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_conv (Conv2D)   (None, 7, 7, 128)    188416      conv5_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_concat (Concatena (None, 7, 7, 1504)   0           conv5_block18_concat[0][0]       \n",
      "                                                                 conv5_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_bn (BatchNormal (None, 7, 7, 1504)   6016        conv5_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_relu (Activatio (None, 7, 7, 1504)   0           conv5_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_conv (Conv2D)   (None, 7, 7, 128)    192512      conv5_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_concat (Concatena (None, 7, 7, 1536)   0           conv5_block19_concat[0][0]       \n",
      "                                                                 conv5_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_bn (BatchNormal (None, 7, 7, 1536)   6144        conv5_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_relu (Activatio (None, 7, 7, 1536)   0           conv5_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_conv (Conv2D)   (None, 7, 7, 128)    196608      conv5_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_concat (Concatena (None, 7, 7, 1568)   0           conv5_block20_concat[0][0]       \n",
      "                                                                 conv5_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_bn (BatchNormal (None, 7, 7, 1568)   6272        conv5_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_relu (Activatio (None, 7, 7, 1568)   0           conv5_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_conv (Conv2D)   (None, 7, 7, 128)    200704      conv5_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_concat (Concatena (None, 7, 7, 1600)   0           conv5_block21_concat[0][0]       \n",
      "                                                                 conv5_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_bn (BatchNormal (None, 7, 7, 1600)   6400        conv5_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_relu (Activatio (None, 7, 7, 1600)   0           conv5_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_conv (Conv2D)   (None, 7, 7, 128)    204800      conv5_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_concat (Concatena (None, 7, 7, 1632)   0           conv5_block22_concat[0][0]       \n",
      "                                                                 conv5_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_bn (BatchNormal (None, 7, 7, 1632)   6528        conv5_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_relu (Activatio (None, 7, 7, 1632)   0           conv5_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_conv (Conv2D)   (None, 7, 7, 128)    208896      conv5_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_concat (Concatena (None, 7, 7, 1664)   0           conv5_block23_concat[0][0]       \n",
      "                                                                 conv5_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_bn (BatchNormal (None, 7, 7, 1664)   6656        conv5_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_relu (Activatio (None, 7, 7, 1664)   0           conv5_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_conv (Conv2D)   (None, 7, 7, 128)    212992      conv5_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_concat (Concatena (None, 7, 7, 1696)   0           conv5_block24_concat[0][0]       \n",
      "                                                                 conv5_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_bn (BatchNormal (None, 7, 7, 1696)   6784        conv5_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_relu (Activatio (None, 7, 7, 1696)   0           conv5_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_conv (Conv2D)   (None, 7, 7, 128)    217088      conv5_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_concat (Concatena (None, 7, 7, 1728)   0           conv5_block25_concat[0][0]       \n",
      "                                                                 conv5_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_bn (BatchNormal (None, 7, 7, 1728)   6912        conv5_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_relu (Activatio (None, 7, 7, 1728)   0           conv5_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_conv (Conv2D)   (None, 7, 7, 128)    221184      conv5_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_concat (Concatena (None, 7, 7, 1760)   0           conv5_block26_concat[0][0]       \n",
      "                                                                 conv5_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_bn (BatchNormal (None, 7, 7, 1760)   7040        conv5_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_relu (Activatio (None, 7, 7, 1760)   0           conv5_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_conv (Conv2D)   (None, 7, 7, 128)    225280      conv5_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_concat (Concatena (None, 7, 7, 1792)   0           conv5_block27_concat[0][0]       \n",
      "                                                                 conv5_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_bn (BatchNormal (None, 7, 7, 1792)   7168        conv5_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_relu (Activatio (None, 7, 7, 1792)   0           conv5_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_conv (Conv2D)   (None, 7, 7, 128)    229376      conv5_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_concat (Concatena (None, 7, 7, 1824)   0           conv5_block28_concat[0][0]       \n",
      "                                                                 conv5_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_bn (BatchNormal (None, 7, 7, 1824)   7296        conv5_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_relu (Activatio (None, 7, 7, 1824)   0           conv5_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_conv (Conv2D)   (None, 7, 7, 128)    233472      conv5_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_concat (Concatena (None, 7, 7, 1856)   0           conv5_block29_concat[0][0]       \n",
      "                                                                 conv5_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_bn (BatchNormal (None, 7, 7, 1856)   7424        conv5_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_relu (Activatio (None, 7, 7, 1856)   0           conv5_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_conv (Conv2D)   (None, 7, 7, 128)    237568      conv5_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 7, 7, 1888)   0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 7, 7, 1888)   7552        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 7, 7, 1888)   0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 7, 7, 128)    241664      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 7, 7, 1920)   0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1920)   7680        conv5_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1920)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1920)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            5763        global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 18,327,747\n",
      "Trainable params: 5,763\n",
      "Non-trainable params: 18,321,984\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(pre_trained_model.output)\n",
    "model_output = tf.keras.layers.Dense(3 , activation='softmax')(x)\n",
    "#x = tf.keras.layers.Flatten()(pre_trained_model.output)\n",
    "\n",
    "model = Model( pre_trained_model.input, model_output, name = 'densenet_type') \n",
    "\n",
    "print(model.summary())\n",
    "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_lr=0.0001, patience=1, verbose=1)\n",
    "\n",
    "filepath=\"./checkpoint/checkpoint-epoch.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/375 [..............................] - ETA: 34s - loss: 1.5294 - accuracy: 0.4219WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 0.1685s). Check your callbacks.\n",
      " 50/375 [===>..........................] - ETA: 58s - loss: 0.7800 - accuracy: 0.6719"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30, validation_split=0.2, callbacks = [tf.keras.callbacks.EarlyStopping(patience = 5, monitor='val_loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  2/375 [..............................] - ETA: 34s - loss: 0.1089 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 0.1695s). Check your callbacks.\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9671\n",
      "Epoch 00001: val_accuracy did not improve from 0.95800\n",
      "375/375 [==============================] - 86s 230ms/step - loss: 0.0992 - accuracy: 0.9671 - val_loss: 0.1210 - val_accuracy: 0.9560\n",
      "Epoch 2/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.9656\n",
      "Epoch 00002: val_accuracy did not improve from 0.95800\n",
      "375/375 [==============================] - 90s 239ms/step - loss: 0.0989 - accuracy: 0.9656 - val_loss: 0.1200 - val_accuracy: 0.9557\n",
      "Epoch 3/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9668\n",
      "Epoch 00003: val_accuracy improved from 0.95800 to 0.95867, saving model to ./checkpoint\\checkpoint-epoch.hdf5\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0983 - accuracy: 0.9668 - val_loss: 0.1202 - val_accuracy: 0.9587\n",
      "Epoch 4/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9672\n",
      "Epoch 00004: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0977 - accuracy: 0.9672 - val_loss: 0.1210 - val_accuracy: 0.9540\n",
      "Epoch 5/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9664\n",
      "Epoch 00005: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0977 - accuracy: 0.9664 - val_loss: 0.1213 - val_accuracy: 0.9530\n",
      "Epoch 6/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9676\n",
      "Epoch 00006: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0969 - accuracy: 0.9676 - val_loss: 0.1199 - val_accuracy: 0.9587\n",
      "Epoch 7/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9661\n",
      "Epoch 00007: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0969 - accuracy: 0.9661 - val_loss: 0.1185 - val_accuracy: 0.9560\n",
      "Epoch 8/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9682\n",
      "Epoch 00008: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0965 - accuracy: 0.9682 - val_loss: 0.1192 - val_accuracy: 0.9547\n",
      "Epoch 9/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9671\n",
      "Epoch 00009: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0958 - accuracy: 0.9671 - val_loss: 0.1178 - val_accuracy: 0.9563\n",
      "Epoch 10/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9679\n",
      "Epoch 00010: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0950 - accuracy: 0.9679 - val_loss: 0.1218 - val_accuracy: 0.9527\n",
      "Epoch 11/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9693\n",
      "Epoch 00011: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0948 - accuracy: 0.9693 - val_loss: 0.1199 - val_accuracy: 0.9537\n",
      "Epoch 12/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9676\n",
      "Epoch 00012: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0947 - accuracy: 0.9676 - val_loss: 0.1175 - val_accuracy: 0.9557\n",
      "Epoch 13/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9674\n",
      "Epoch 00013: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0941 - accuracy: 0.9674 - val_loss: 0.1181 - val_accuracy: 0.9550\n",
      "Epoch 14/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9675\n",
      "Epoch 00014: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0941 - accuracy: 0.9675 - val_loss: 0.1170 - val_accuracy: 0.9570\n",
      "Epoch 15/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9690\n",
      "Epoch 00015: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0932 - accuracy: 0.9690 - val_loss: 0.1168 - val_accuracy: 0.9557\n",
      "Epoch 16/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9686\n",
      "Epoch 00016: val_accuracy did not improve from 0.95867\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0926 - accuracy: 0.9686 - val_loss: 0.1158 - val_accuracy: 0.9557\n",
      "Epoch 17/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9693\n",
      "Epoch 00017: val_accuracy improved from 0.95867 to 0.95900, saving model to ./checkpoint\\checkpoint-epoch.hdf5\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0924 - accuracy: 0.9693 - val_loss: 0.1216 - val_accuracy: 0.9590\n",
      "Epoch 18/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9693\n",
      "Epoch 00018: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0926 - accuracy: 0.9693 - val_loss: 0.1160 - val_accuracy: 0.9567\n",
      "Epoch 19/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9690\n",
      "Epoch 00019: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0918 - accuracy: 0.9690 - val_loss: 0.1163 - val_accuracy: 0.9550\n",
      "Epoch 20/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9695\n",
      "Epoch 00020: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0911 - accuracy: 0.9695 - val_loss: 0.1167 - val_accuracy: 0.9577\n",
      "Epoch 21/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.9698\n",
      "Epoch 00021: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0913 - accuracy: 0.9698 - val_loss: 0.1160 - val_accuracy: 0.9557\n",
      "Epoch 22/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 0.9693\n",
      "Epoch 00022: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0912 - accuracy: 0.9693 - val_loss: 0.1220 - val_accuracy: 0.9543\n",
      "Epoch 23/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.9700\n",
      "Epoch 00023: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0905 - accuracy: 0.9700 - val_loss: 0.1146 - val_accuracy: 0.9563\n",
      "Epoch 24/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9692\n",
      "Epoch 00024: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 94s 251ms/step - loss: 0.0904 - accuracy: 0.9692 - val_loss: 0.1156 - val_accuracy: 0.9560\n",
      "Epoch 25/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9697\n",
      "Epoch 00025: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 95s 252ms/step - loss: 0.0895 - accuracy: 0.9697 - val_loss: 0.1156 - val_accuracy: 0.9577\n",
      "Epoch 26/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9700\n",
      "Epoch 00026: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 94s 250ms/step - loss: 0.0894 - accuracy: 0.9700 - val_loss: 0.1143 - val_accuracy: 0.9590\n",
      "Epoch 27/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9700\n",
      "Epoch 00027: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0892 - accuracy: 0.9700 - val_loss: 0.1150 - val_accuracy: 0.9560\n",
      "Epoch 28/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9703\n",
      "Epoch 00028: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0890 - accuracy: 0.9703 - val_loss: 0.1145 - val_accuracy: 0.9570\n",
      "Epoch 29/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9702\n",
      "Epoch 00029: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0888 - accuracy: 0.9702 - val_loss: 0.1155 - val_accuracy: 0.9563\n",
      "Epoch 30/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.9702\n",
      "Epoch 00030: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0887 - accuracy: 0.9702 - val_loss: 0.1145 - val_accuracy: 0.9583\n",
      "Epoch 31/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9707\n",
      "Epoch 00031: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0878 - accuracy: 0.9707 - val_loss: 0.1134 - val_accuracy: 0.9567\n",
      "Epoch 32/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9702\n",
      "Epoch 00032: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0875 - accuracy: 0.9702 - val_loss: 0.1149 - val_accuracy: 0.9570\n",
      "Epoch 33/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9707\n",
      "Epoch 00033: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0870 - accuracy: 0.9707 - val_loss: 0.1131 - val_accuracy: 0.9563\n",
      "Epoch 34/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9700\n",
      "Epoch 00034: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0866 - accuracy: 0.9700 - val_loss: 0.1135 - val_accuracy: 0.9587\n",
      "Epoch 35/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9720\n",
      "Epoch 00035: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0869 - accuracy: 0.9720 - val_loss: 0.1125 - val_accuracy: 0.9583\n",
      "Epoch 36/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9709\n",
      "Epoch 00036: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0865 - accuracy: 0.9709 - val_loss: 0.1146 - val_accuracy: 0.9563\n",
      "Epoch 37/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9701\n",
      "Epoch 00037: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0861 - accuracy: 0.9701 - val_loss: 0.1143 - val_accuracy: 0.9573\n",
      "Epoch 38/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9704\n",
      "Epoch 00038: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 92s 247ms/step - loss: 0.0858 - accuracy: 0.9704 - val_loss: 0.1161 - val_accuracy: 0.9550\n",
      "Epoch 39/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9703\n",
      "Epoch 00039: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0857 - accuracy: 0.9703 - val_loss: 0.1134 - val_accuracy: 0.9577\n",
      "Epoch 40/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9714\n",
      "Epoch 00040: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0852 - accuracy: 0.9714 - val_loss: 0.1137 - val_accuracy: 0.9570\n",
      "Epoch 41/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9720\n",
      "Epoch 00041: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0855 - accuracy: 0.9720 - val_loss: 0.1120 - val_accuracy: 0.9573\n",
      "Epoch 42/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9707\n",
      "Epoch 00042: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0850 - accuracy: 0.9707 - val_loss: 0.1134 - val_accuracy: 0.9557\n",
      "Epoch 43/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9720\n",
      "Epoch 00043: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0844 - accuracy: 0.9720 - val_loss: 0.1135 - val_accuracy: 0.9567\n",
      "Epoch 44/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9723\n",
      "Epoch 00044: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0842 - accuracy: 0.9723 - val_loss: 0.1147 - val_accuracy: 0.9550\n",
      "Epoch 45/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9716\n",
      "Epoch 00045: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0840 - accuracy: 0.9716 - val_loss: 0.1108 - val_accuracy: 0.9580\n",
      "Epoch 46/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9726\n",
      "Epoch 00046: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0836 - accuracy: 0.9726 - val_loss: 0.1109 - val_accuracy: 0.9580\n",
      "Epoch 47/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9726\n",
      "Epoch 00047: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0834 - accuracy: 0.9726 - val_loss: 0.1102 - val_accuracy: 0.9577\n",
      "Epoch 48/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9721\n",
      "Epoch 00048: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0830 - accuracy: 0.9721 - val_loss: 0.1115 - val_accuracy: 0.9573\n",
      "Epoch 49/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9722\n",
      "Epoch 00049: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0830 - accuracy: 0.9722 - val_loss: 0.1099 - val_accuracy: 0.9587\n",
      "Epoch 50/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9722\n",
      "Epoch 00050: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0828 - accuracy: 0.9722 - val_loss: 0.1115 - val_accuracy: 0.9563\n",
      "Epoch 51/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9722\n",
      "Epoch 00051: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0829 - accuracy: 0.9722 - val_loss: 0.1097 - val_accuracy: 0.9577\n",
      "Epoch 52/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9725\n",
      "Epoch 00052: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0824 - accuracy: 0.9725 - val_loss: 0.1111 - val_accuracy: 0.9573\n",
      "Epoch 53/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9721\n",
      "Epoch 00053: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0819 - accuracy: 0.9721 - val_loss: 0.1103 - val_accuracy: 0.9587\n",
      "Epoch 54/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9723\n",
      "Epoch 00054: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0828 - accuracy: 0.9723 - val_loss: 0.1094 - val_accuracy: 0.9577\n",
      "Epoch 55/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9731\n",
      "Epoch 00055: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0817 - accuracy: 0.9731 - val_loss: 0.1108 - val_accuracy: 0.9570\n",
      "Epoch 56/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.9732\n",
      "Epoch 00056: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0813 - accuracy: 0.9732 - val_loss: 0.1115 - val_accuracy: 0.9587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9737\n",
      "Epoch 00057: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0810 - accuracy: 0.9737 - val_loss: 0.1094 - val_accuracy: 0.9587\n",
      "Epoch 58/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9732\n",
      "Epoch 00058: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0811 - accuracy: 0.9732 - val_loss: 0.1109 - val_accuracy: 0.9590\n",
      "Epoch 59/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9740\n",
      "Epoch 00059: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0803 - accuracy: 0.9740 - val_loss: 0.1095 - val_accuracy: 0.9587\n",
      "Epoch 60/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9732\n",
      "Epoch 00060: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0803 - accuracy: 0.9732 - val_loss: 0.1100 - val_accuracy: 0.9587\n",
      "Epoch 61/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9732\n",
      "Epoch 00061: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0803 - accuracy: 0.9732 - val_loss: 0.1113 - val_accuracy: 0.9573\n",
      "Epoch 62/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9747\n",
      "Epoch 00062: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0800 - accuracy: 0.9747 - val_loss: 0.1088 - val_accuracy: 0.9587\n",
      "Epoch 63/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9722\n",
      "Epoch 00063: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0803 - accuracy: 0.9722 - val_loss: 0.1086 - val_accuracy: 0.9573\n",
      "Epoch 64/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9732\n",
      "Epoch 00064: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0801 - accuracy: 0.9732 - val_loss: 0.1087 - val_accuracy: 0.9583\n",
      "Epoch 65/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9729\n",
      "Epoch 00065: val_accuracy did not improve from 0.95900\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0797 - accuracy: 0.9729 - val_loss: 0.1085 - val_accuracy: 0.9583\n",
      "Epoch 66/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9737\n",
      "Epoch 00066: val_accuracy improved from 0.95900 to 0.95933, saving model to ./checkpoint\\checkpoint-epoch.hdf5\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0789 - accuracy: 0.9737 - val_loss: 0.1088 - val_accuracy: 0.9593\n",
      "Epoch 67/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9734\n",
      "Epoch 00067: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0793 - accuracy: 0.9734 - val_loss: 0.1089 - val_accuracy: 0.9577\n",
      "Epoch 68/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9741\n",
      "Epoch 00068: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0785 - accuracy: 0.9741 - val_loss: 0.1082 - val_accuracy: 0.9573\n",
      "Epoch 69/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9739\n",
      "Epoch 00069: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0790 - accuracy: 0.9739 - val_loss: 0.1082 - val_accuracy: 0.9573\n",
      "Epoch 70/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9731\n",
      "Epoch 00070: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 94s 250ms/step - loss: 0.0786 - accuracy: 0.9731 - val_loss: 0.1080 - val_accuracy: 0.9583\n",
      "Epoch 71/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9744\n",
      "Epoch 00071: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0784 - accuracy: 0.9744 - val_loss: 0.1106 - val_accuracy: 0.9570\n",
      "Epoch 72/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9742\n",
      "Epoch 00072: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0781 - accuracy: 0.9742 - val_loss: 0.1072 - val_accuracy: 0.9587\n",
      "Epoch 73/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9735\n",
      "Epoch 00073: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0780 - accuracy: 0.9735 - val_loss: 0.1087 - val_accuracy: 0.9570\n",
      "Epoch 74/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9743\n",
      "Epoch 00074: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0777 - accuracy: 0.9743 - val_loss: 0.1071 - val_accuracy: 0.9573\n",
      "Epoch 75/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9740\n",
      "Epoch 00075: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0773 - accuracy: 0.9740 - val_loss: 0.1079 - val_accuracy: 0.9580\n",
      "Epoch 76/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9743\n",
      "Epoch 00076: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0771 - accuracy: 0.9743 - val_loss: 0.1076 - val_accuracy: 0.9580\n",
      "Epoch 77/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9744\n",
      "Epoch 00077: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0773 - accuracy: 0.9744 - val_loss: 0.1070 - val_accuracy: 0.9580\n",
      "Epoch 78/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9730\n",
      "Epoch 00078: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0765 - accuracy: 0.9730 - val_loss: 0.1087 - val_accuracy: 0.9587\n",
      "Epoch 79/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9742\n",
      "Epoch 00079: val_accuracy did not improve from 0.95933\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0762 - accuracy: 0.9742 - val_loss: 0.1066 - val_accuracy: 0.9590\n",
      "Epoch 80/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9734\n",
      "Epoch 00080: val_accuracy improved from 0.95933 to 0.95967, saving model to ./checkpoint\\checkpoint-epoch.hdf5\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0765 - accuracy: 0.9734 - val_loss: 0.1083 - val_accuracy: 0.9597\n",
      "Epoch 81/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9744\n",
      "Epoch 00081: val_accuracy did not improve from 0.95967\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0770 - accuracy: 0.9744 - val_loss: 0.1074 - val_accuracy: 0.9580\n",
      "Epoch 82/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9744\n",
      "Epoch 00082: val_accuracy did not improve from 0.95967\n",
      "375/375 [==============================] - 94s 251ms/step - loss: 0.0766 - accuracy: 0.9744 - val_loss: 0.1065 - val_accuracy: 0.9597\n",
      "Epoch 83/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9748\n",
      "Epoch 00083: val_accuracy did not improve from 0.95967\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0764 - accuracy: 0.9748 - val_loss: 0.1076 - val_accuracy: 0.9573\n",
      "Epoch 84/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.9736\n",
      "Epoch 00084: val_accuracy did not improve from 0.95967\n",
      "375/375 [==============================] - 94s 249ms/step - loss: 0.0759 - accuracy: 0.9736 - val_loss: 0.1094 - val_accuracy: 0.9587\n",
      "Epoch 85/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9743\n",
      "Epoch 00085: val_accuracy did not improve from 0.95967\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0763 - accuracy: 0.9743 - val_loss: 0.1063 - val_accuracy: 0.9567\n",
      "Epoch 86/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9747\n",
      "Epoch 00086: val_accuracy did not improve from 0.95967\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0761 - accuracy: 0.9747 - val_loss: 0.1074 - val_accuracy: 0.9573\n",
      "Epoch 87/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9748\n",
      "Epoch 00087: val_accuracy did not improve from 0.95967\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0754 - accuracy: 0.9748 - val_loss: 0.1082 - val_accuracy: 0.9580\n",
      "Epoch 88/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9755\n",
      "Epoch 00088: val_accuracy improved from 0.95967 to 0.96067, saving model to ./checkpoint\\checkpoint-epoch.hdf5\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0753 - accuracy: 0.9755 - val_loss: 0.1069 - val_accuracy: 0.9607\n",
      "Epoch 89/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9753\n",
      "Epoch 00089: val_accuracy did not improve from 0.96067\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0754 - accuracy: 0.9753 - val_loss: 0.1064 - val_accuracy: 0.9573\n",
      "Epoch 90/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9758\n",
      "Epoch 00090: val_accuracy did not improve from 0.96067\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0750 - accuracy: 0.9758 - val_loss: 0.1061 - val_accuracy: 0.9590\n",
      "Epoch 91/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9749\n",
      "Epoch 00091: val_accuracy did not improve from 0.96067\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0749 - accuracy: 0.9749 - val_loss: 0.1063 - val_accuracy: 0.9590\n",
      "Epoch 92/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9750\n",
      "Epoch 00092: val_accuracy did not improve from 0.96067\n",
      "375/375 [==============================] - 94s 250ms/step - loss: 0.0750 - accuracy: 0.9750 - val_loss: 0.1070 - val_accuracy: 0.9607\n",
      "Epoch 93/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9757\n",
      "Epoch 00093: val_accuracy did not improve from 0.96067\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0743 - accuracy: 0.9757 - val_loss: 0.1075 - val_accuracy: 0.9600\n",
      "Epoch 94/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9756\n",
      "Epoch 00094: val_accuracy did not improve from 0.96067\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0743 - accuracy: 0.9756 - val_loss: 0.1094 - val_accuracy: 0.9563\n",
      "Epoch 95/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9755\n",
      "Epoch 00095: val_accuracy did not improve from 0.96067\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0742 - accuracy: 0.9755 - val_loss: 0.1067 - val_accuracy: 0.9577\n",
      "Epoch 96/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9759\n",
      "Epoch 00096: val_accuracy did not improve from 0.96067\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0742 - accuracy: 0.9759 - val_loss: 0.1069 - val_accuracy: 0.9580\n",
      "Epoch 97/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9758\n",
      "Epoch 00097: val_accuracy did not improve from 0.96067\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0739 - accuracy: 0.9758 - val_loss: 0.1098 - val_accuracy: 0.9570\n",
      "Epoch 98/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9757\n",
      "Epoch 00098: val_accuracy did not improve from 0.96067\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0740 - accuracy: 0.9757 - val_loss: 0.1065 - val_accuracy: 0.9573\n",
      "Epoch 99/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9754\n",
      "Epoch 00099: val_accuracy did not improve from 0.96067\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0734 - accuracy: 0.9754 - val_loss: 0.1079 - val_accuracy: 0.9580\n",
      "Epoch 100/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9757\n",
      "Epoch 00100: val_accuracy improved from 0.96067 to 0.96100, saving model to ./checkpoint\\checkpoint-epoch.hdf5\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0729 - accuracy: 0.9757 - val_loss: 0.1065 - val_accuracy: 0.9610\n",
      "Epoch 101/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9768\n",
      "Epoch 00101: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0731 - accuracy: 0.9768 - val_loss: 0.1096 - val_accuracy: 0.9577\n",
      "Epoch 102/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 0.9754\n",
      "Epoch 00102: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0732 - accuracy: 0.9754 - val_loss: 0.1047 - val_accuracy: 0.9593\n",
      "Epoch 103/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9762\n",
      "Epoch 00103: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 95s 252ms/step - loss: 0.0729 - accuracy: 0.9762 - val_loss: 0.1049 - val_accuracy: 0.9567\n",
      "Epoch 104/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9763\n",
      "Epoch 00104: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 94s 251ms/step - loss: 0.0726 - accuracy: 0.9763 - val_loss: 0.1081 - val_accuracy: 0.9570\n",
      "Epoch 105/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9761\n",
      "Epoch 00105: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 94s 249ms/step - loss: 0.0727 - accuracy: 0.9761 - val_loss: 0.1076 - val_accuracy: 0.9570\n",
      "Epoch 106/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9765\n",
      "Epoch 00106: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0726 - accuracy: 0.9765 - val_loss: 0.1100 - val_accuracy: 0.9600\n",
      "Epoch 107/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9758\n",
      "Epoch 00107: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0729 - accuracy: 0.9758 - val_loss: 0.1052 - val_accuracy: 0.9587\n",
      "Epoch 108/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.97 - ETA: 0s - loss: 0.0727 - accuracy: 0.9757\n",
      "Epoch 00108: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0727 - accuracy: 0.9757 - val_loss: 0.1047 - val_accuracy: 0.9587\n",
      "Epoch 109/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9754\n",
      "Epoch 00109: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0724 - accuracy: 0.9754 - val_loss: 0.1050 - val_accuracy: 0.9593\n",
      "Epoch 110/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9765\n",
      "Epoch 00110: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 247ms/step - loss: 0.0717 - accuracy: 0.9765 - val_loss: 0.1064 - val_accuracy: 0.9573\n",
      "Epoch 111/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9763\n",
      "Epoch 00111: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0718 - accuracy: 0.9763 - val_loss: 0.1059 - val_accuracy: 0.9567\n",
      "Epoch 112/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9754\n",
      "Epoch 00112: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0717 - accuracy: 0.9754 - val_loss: 0.1064 - val_accuracy: 0.9573\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9760\n",
      "Epoch 00113: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0711 - accuracy: 0.9760 - val_loss: 0.1047 - val_accuracy: 0.9600\n",
      "Epoch 114/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9761\n",
      "Epoch 00114: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0711 - accuracy: 0.9761 - val_loss: 0.1045 - val_accuracy: 0.9593\n",
      "Epoch 115/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9763\n",
      "Epoch 00115: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0717 - accuracy: 0.9763 - val_loss: 0.1034 - val_accuracy: 0.9587\n",
      "Epoch 116/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9775\n",
      "Epoch 00116: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0713 - accuracy: 0.9775 - val_loss: 0.1036 - val_accuracy: 0.9580\n",
      "Epoch 117/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9762\n",
      "Epoch 00117: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0712 - accuracy: 0.9762 - val_loss: 0.1053 - val_accuracy: 0.9570\n",
      "Epoch 118/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9763\n",
      "Epoch 00118: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0707 - accuracy: 0.9763 - val_loss: 0.1145 - val_accuracy: 0.9563\n",
      "Epoch 119/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9766\n",
      "Epoch 00119: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0711 - accuracy: 0.9766 - val_loss: 0.1039 - val_accuracy: 0.9567\n",
      "Epoch 120/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9769\n",
      "Epoch 00120: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0707 - accuracy: 0.9769 - val_loss: 0.1034 - val_accuracy: 0.9573\n",
      "Epoch 121/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9770\n",
      "Epoch 00121: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0702 - accuracy: 0.9770 - val_loss: 0.1048 - val_accuracy: 0.9580\n",
      "Epoch 122/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9779\n",
      "Epoch 00122: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0704 - accuracy: 0.9779 - val_loss: 0.1035 - val_accuracy: 0.9577\n",
      "Epoch 123/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9771\n",
      "Epoch 00123: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0704 - accuracy: 0.9771 - val_loss: 0.1043 - val_accuracy: 0.9583\n",
      "Epoch 124/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9768\n",
      "Epoch 00124: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0706 - accuracy: 0.9768 - val_loss: 0.1033 - val_accuracy: 0.9570\n",
      "Epoch 125/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9772\n",
      "Epoch 00125: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0700 - accuracy: 0.9772 - val_loss: 0.1052 - val_accuracy: 0.9573\n",
      "Epoch 126/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9772\n",
      "Epoch 00126: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0701 - accuracy: 0.9772 - val_loss: 0.1080 - val_accuracy: 0.9553\n",
      "Epoch 127/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9777\n",
      "Epoch 00127: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0696 - accuracy: 0.9777 - val_loss: 0.1032 - val_accuracy: 0.9593\n",
      "Epoch 128/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9770\n",
      "Epoch 00128: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0695 - accuracy: 0.9770 - val_loss: 0.1035 - val_accuracy: 0.9567\n",
      "Epoch 129/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9782\n",
      "Epoch 00129: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0696 - accuracy: 0.9782 - val_loss: 0.1034 - val_accuracy: 0.9593\n",
      "Epoch 130/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9771\n",
      "Epoch 00130: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0692 - accuracy: 0.9771 - val_loss: 0.1083 - val_accuracy: 0.9577\n",
      "Epoch 131/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9762\n",
      "Epoch 00131: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 247ms/step - loss: 0.0696 - accuracy: 0.9762 - val_loss: 0.1033 - val_accuracy: 0.9560\n",
      "Epoch 132/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9786\n",
      "Epoch 00132: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0690 - accuracy: 0.9786 - val_loss: 0.1044 - val_accuracy: 0.9567\n",
      "Epoch 133/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9781\n",
      "Epoch 00133: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0693 - accuracy: 0.9781 - val_loss: 0.1029 - val_accuracy: 0.9577\n",
      "Epoch 134/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9776\n",
      "Epoch 00134: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0689 - accuracy: 0.9776 - val_loss: 0.1030 - val_accuracy: 0.9563\n",
      "Epoch 135/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9772\n",
      "Epoch 00135: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0689 - accuracy: 0.9772 - val_loss: 0.1033 - val_accuracy: 0.9570\n",
      "Epoch 136/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9774\n",
      "Epoch 00136: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0683 - accuracy: 0.9774 - val_loss: 0.1024 - val_accuracy: 0.9590\n",
      "Epoch 137/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9783\n",
      "Epoch 00137: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 247ms/step - loss: 0.0687 - accuracy: 0.9783 - val_loss: 0.1047 - val_accuracy: 0.9563\n",
      "Epoch 138/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9768\n",
      "Epoch 00138: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 247ms/step - loss: 0.0683 - accuracy: 0.9768 - val_loss: 0.1033 - val_accuracy: 0.9600\n",
      "Epoch 139/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9770\n",
      "Epoch 00139: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0684 - accuracy: 0.9770 - val_loss: 0.1032 - val_accuracy: 0.9577\n",
      "Epoch 140/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9782\n",
      "Epoch 00140: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0687 - accuracy: 0.9782 - val_loss: 0.1031 - val_accuracy: 0.9567\n",
      "Epoch 141/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9777\n",
      "Epoch 00141: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 248ms/step - loss: 0.0688 - accuracy: 0.9777 - val_loss: 0.1032 - val_accuracy: 0.9573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9783\n",
      "Epoch 00142: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0682 - accuracy: 0.9783 - val_loss: 0.1030 - val_accuracy: 0.9567\n",
      "Epoch 143/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.9783\n",
      "Epoch 00143: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0679 - accuracy: 0.9783 - val_loss: 0.1039 - val_accuracy: 0.9563\n",
      "Epoch 144/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.9786\n",
      "Epoch 00144: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0679 - accuracy: 0.9786 - val_loss: 0.1036 - val_accuracy: 0.9590\n",
      "Epoch 145/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9787\n",
      "Epoch 00145: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0676 - accuracy: 0.9787 - val_loss: 0.1023 - val_accuracy: 0.9570\n",
      "Epoch 146/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9780\n",
      "Epoch 00146: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0676 - accuracy: 0.9780 - val_loss: 0.1022 - val_accuracy: 0.9600\n",
      "Epoch 147/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9779\n",
      "Epoch 00147: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0672 - accuracy: 0.9779 - val_loss: 0.1064 - val_accuracy: 0.9583\n",
      "Epoch 148/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9784\n",
      "Epoch 00148: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0673 - accuracy: 0.9784 - val_loss: 0.1025 - val_accuracy: 0.9573\n",
      "Epoch 149/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9777\n",
      "Epoch 00149: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0672 - accuracy: 0.9777 - val_loss: 0.1021 - val_accuracy: 0.9600\n",
      "Epoch 150/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9783\n",
      "Epoch 00150: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0672 - accuracy: 0.9783 - val_loss: 0.1027 - val_accuracy: 0.9570\n",
      "Epoch 151/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9778\n",
      "Epoch 00151: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0667 - accuracy: 0.9778 - val_loss: 0.1097 - val_accuracy: 0.9587\n",
      "Epoch 152/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9777\n",
      "Epoch 00152: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0671 - accuracy: 0.9777 - val_loss: 0.1036 - val_accuracy: 0.9567\n",
      "Epoch 153/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9789\n",
      "Epoch 00153: val_accuracy did not improve from 0.96100\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0671 - accuracy: 0.9789 - val_loss: 0.1025 - val_accuracy: 0.9570\n",
      "Epoch 154/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9789\n",
      "Epoch 00154: val_accuracy improved from 0.96100 to 0.96233, saving model to ./checkpoint\\checkpoint-epoch.hdf5\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0669 - accuracy: 0.9789 - val_loss: 0.1045 - val_accuracy: 0.9623\n",
      "Epoch 155/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9781\n",
      "Epoch 00155: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0668 - accuracy: 0.9781 - val_loss: 0.1033 - val_accuracy: 0.9613\n",
      "Epoch 156/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9789\n",
      "Epoch 00156: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0667 - accuracy: 0.9789 - val_loss: 0.1034 - val_accuracy: 0.9573\n",
      "Epoch 157/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9790\n",
      "Epoch 00157: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0663 - accuracy: 0.9790 - val_loss: 0.1018 - val_accuracy: 0.9560\n",
      "Epoch 158/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9787\n",
      "Epoch 00158: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0669 - accuracy: 0.9787 - val_loss: 0.1012 - val_accuracy: 0.9587\n",
      "Epoch 159/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9788\n",
      "Epoch 00159: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 247ms/step - loss: 0.0660 - accuracy: 0.9788 - val_loss: 0.1022 - val_accuracy: 0.9603\n",
      "Epoch 160/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9783\n",
      "Epoch 00160: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0661 - accuracy: 0.9783 - val_loss: 0.1028 - val_accuracy: 0.9567\n",
      "Epoch 161/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9789\n",
      "Epoch 00161: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0668 - accuracy: 0.9789 - val_loss: 0.1059 - val_accuracy: 0.9570\n",
      "Epoch 162/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9791\n",
      "Epoch 00162: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0666 - accuracy: 0.9791 - val_loss: 0.1032 - val_accuracy: 0.9573\n",
      "Epoch 163/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9786\n",
      "Epoch 00163: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 247ms/step - loss: 0.0661 - accuracy: 0.9786 - val_loss: 0.1032 - val_accuracy: 0.9587\n",
      "Epoch 164/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9793\n",
      "Epoch 00164: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0661 - accuracy: 0.9793 - val_loss: 0.1054 - val_accuracy: 0.9573\n",
      "Epoch 165/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9787\n",
      "Epoch 00165: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0655 - accuracy: 0.9787 - val_loss: 0.1054 - val_accuracy: 0.9580\n",
      "Epoch 166/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9790\n",
      "Epoch 00166: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0658 - accuracy: 0.9790 - val_loss: 0.1023 - val_accuracy: 0.9583\n",
      "Epoch 167/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9791\n",
      "Epoch 00167: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0656 - accuracy: 0.9791 - val_loss: 0.1019 - val_accuracy: 0.9570\n",
      "Epoch 168/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9791\n",
      "Epoch 00168: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0652 - accuracy: 0.9791 - val_loss: 0.1018 - val_accuracy: 0.9603\n",
      "Epoch 169/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9783\n",
      "Epoch 00169: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0653 - accuracy: 0.9783 - val_loss: 0.1076 - val_accuracy: 0.9583\n",
      "Epoch 170/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9787\n",
      "Epoch 00170: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0656 - accuracy: 0.9787 - val_loss: 0.1016 - val_accuracy: 0.9610\n",
      "Epoch 171/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9798\n",
      "Epoch 00171: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0652 - accuracy: 0.9798 - val_loss: 0.1017 - val_accuracy: 0.9603\n",
      "Epoch 172/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9795\n",
      "Epoch 00172: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0648 - accuracy: 0.9795 - val_loss: 0.1024 - val_accuracy: 0.9570\n",
      "Epoch 173/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9793\n",
      "Epoch 00173: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0650 - accuracy: 0.9793 - val_loss: 0.1026 - val_accuracy: 0.9577\n",
      "Epoch 174/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9788\n",
      "Epoch 00174: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0651 - accuracy: 0.9788 - val_loss: 0.1022 - val_accuracy: 0.9567\n",
      "Epoch 175/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9799\n",
      "Epoch 00175: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 244ms/step - loss: 0.0648 - accuracy: 0.9799 - val_loss: 0.1023 - val_accuracy: 0.9567\n",
      "Epoch 176/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9799\n",
      "Epoch 00176: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0648 - accuracy: 0.9799 - val_loss: 0.1019 - val_accuracy: 0.9563\n",
      "Epoch 177/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9792\n",
      "Epoch 00177: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0643 - accuracy: 0.9792 - val_loss: 0.1010 - val_accuracy: 0.9573\n",
      "Epoch 178/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9797\n",
      "Epoch 00178: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0645 - accuracy: 0.9797 - val_loss: 0.1013 - val_accuracy: 0.9567\n",
      "Epoch 179/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9787\n",
      "Epoch 00179: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0645 - accuracy: 0.9787 - val_loss: 0.1036 - val_accuracy: 0.9580\n",
      "Epoch 180/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9793\n",
      "Epoch 00180: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0642 - accuracy: 0.9793 - val_loss: 0.1008 - val_accuracy: 0.9563\n",
      "Epoch 181/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9789\n",
      "Epoch 00181: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 0.1022 - val_accuracy: 0.9567\n",
      "Epoch 182/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9787\n",
      "Epoch 00182: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0643 - accuracy: 0.9787 - val_loss: 0.1010 - val_accuracy: 0.9593\n",
      "Epoch 183/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9790\n",
      "Epoch 00183: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0640 - accuracy: 0.9790 - val_loss: 0.1013 - val_accuracy: 0.9590\n",
      "Epoch 184/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9795\n",
      "Epoch 00184: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0640 - accuracy: 0.9795 - val_loss: 0.1011 - val_accuracy: 0.9567\n",
      "Epoch 185/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9798\n",
      "Epoch 00185: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0637 - accuracy: 0.9798 - val_loss: 0.1021 - val_accuracy: 0.9570\n",
      "Epoch 186/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9790\n",
      "Epoch 00186: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0642 - accuracy: 0.9790 - val_loss: 0.1006 - val_accuracy: 0.9583\n",
      "Epoch 187/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9808\n",
      "Epoch 00187: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0639 - accuracy: 0.9808 - val_loss: 0.1012 - val_accuracy: 0.9587\n",
      "Epoch 188/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9800\n",
      "Epoch 00188: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0641 - accuracy: 0.9800 - val_loss: 0.1013 - val_accuracy: 0.9573\n",
      "Epoch 189/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9792\n",
      "Epoch 00189: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0638 - accuracy: 0.9792 - val_loss: 0.1033 - val_accuracy: 0.9577\n",
      "Epoch 190/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9802\n",
      "Epoch 00190: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0635 - accuracy: 0.9802 - val_loss: 0.1015 - val_accuracy: 0.9560\n",
      "Epoch 191/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9797\n",
      "Epoch 00191: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0634 - accuracy: 0.9797 - val_loss: 0.1023 - val_accuracy: 0.9583\n",
      "Epoch 192/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9799\n",
      "Epoch 00192: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0634 - accuracy: 0.9799 - val_loss: 0.1027 - val_accuracy: 0.9613\n",
      "Epoch 193/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9800\n",
      "Epoch 00193: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0635 - accuracy: 0.9800 - val_loss: 0.1006 - val_accuracy: 0.9577\n",
      "Epoch 194/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9800\n",
      "Epoch 00194: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0630 - accuracy: 0.9800 - val_loss: 0.1007 - val_accuracy: 0.9573\n",
      "Epoch 195/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9795\n",
      "Epoch 00195: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0630 - accuracy: 0.9795 - val_loss: 0.1003 - val_accuracy: 0.9590\n",
      "Epoch 196/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9798\n",
      "Epoch 00196: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0627 - accuracy: 0.9798 - val_loss: 0.1004 - val_accuracy: 0.9573\n",
      "Epoch 197/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9793\n",
      "Epoch 00197: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0631 - accuracy: 0.9793 - val_loss: 0.1001 - val_accuracy: 0.9583\n",
      "Epoch 198/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9799\n",
      "Epoch 00198: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0625 - accuracy: 0.9799 - val_loss: 0.1002 - val_accuracy: 0.9587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9801\n",
      "Epoch 00199: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0627 - accuracy: 0.9801 - val_loss: 0.1011 - val_accuracy: 0.9577\n",
      "Epoch 200/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9803\n",
      "Epoch 00200: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0625 - accuracy: 0.9803 - val_loss: 0.1019 - val_accuracy: 0.9580\n",
      "Epoch 201/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9803\n",
      "Epoch 00201: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0626 - accuracy: 0.9803 - val_loss: 0.0999 - val_accuracy: 0.9587\n",
      "Epoch 202/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9796\n",
      "Epoch 00202: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0625 - accuracy: 0.9796 - val_loss: 0.1007 - val_accuracy: 0.9577\n",
      "Epoch 203/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9795\n",
      "Epoch 00203: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0624 - accuracy: 0.9795 - val_loss: 0.1007 - val_accuracy: 0.9567\n",
      "Epoch 204/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9801\n",
      "Epoch 00204: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0621 - accuracy: 0.9801 - val_loss: 0.1005 - val_accuracy: 0.9593\n",
      "Epoch 205/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9801\n",
      "Epoch 00205: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0625 - accuracy: 0.9801 - val_loss: 0.1016 - val_accuracy: 0.9583\n",
      "Epoch 206/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9795\n",
      "Epoch 00206: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0621 - accuracy: 0.9795 - val_loss: 0.1047 - val_accuracy: 0.9583\n",
      "Epoch 207/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9809\n",
      "Epoch 00207: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0622 - accuracy: 0.9809 - val_loss: 0.1001 - val_accuracy: 0.9563\n",
      "Epoch 208/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9803\n",
      "Epoch 00208: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0618 - accuracy: 0.9803 - val_loss: 0.1014 - val_accuracy: 0.9583\n",
      "Epoch 209/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9808\n",
      "Epoch 00209: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 94s 250ms/step - loss: 0.0619 - accuracy: 0.9808 - val_loss: 0.1020 - val_accuracy: 0.9610\n",
      "Epoch 210/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9793\n",
      "Epoch 00210: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0617 - accuracy: 0.9793 - val_loss: 0.1007 - val_accuracy: 0.9593\n",
      "Epoch 211/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9798\n",
      "Epoch 00211: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0618 - accuracy: 0.9798 - val_loss: 0.1029 - val_accuracy: 0.9580\n",
      "Epoch 212/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9796\n",
      "Epoch 00212: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0617 - accuracy: 0.9796 - val_loss: 0.1009 - val_accuracy: 0.9600\n",
      "Epoch 213/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9808\n",
      "Epoch 00213: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0616 - accuracy: 0.9808 - val_loss: 0.1016 - val_accuracy: 0.9583\n",
      "Epoch 214/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9806\n",
      "Epoch 00214: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0617 - accuracy: 0.9806 - val_loss: 0.1003 - val_accuracy: 0.9600\n",
      "Epoch 215/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9808\n",
      "Epoch 00215: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0616 - accuracy: 0.9808 - val_loss: 0.1010 - val_accuracy: 0.9570\n",
      "Epoch 216/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9812\n",
      "Epoch 00216: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0615 - accuracy: 0.9812 - val_loss: 0.1004 - val_accuracy: 0.9590\n",
      "Epoch 217/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9799\n",
      "Epoch 00217: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 93s 249ms/step - loss: 0.0613 - accuracy: 0.9799 - val_loss: 0.1003 - val_accuracy: 0.9590\n",
      "Epoch 218/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9802\n",
      "Epoch 00218: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0611 - accuracy: 0.9802 - val_loss: 0.1009 - val_accuracy: 0.9583\n",
      "Epoch 219/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9800\n",
      "Epoch 00219: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0613 - accuracy: 0.9800 - val_loss: 0.0999 - val_accuracy: 0.9593\n",
      "Epoch 220/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9810\n",
      "Epoch 00220: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 246ms/step - loss: 0.0612 - accuracy: 0.9810 - val_loss: 0.0994 - val_accuracy: 0.9580\n",
      "Epoch 221/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9806\n",
      "Epoch 00221: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0609 - accuracy: 0.9806 - val_loss: 0.1005 - val_accuracy: 0.9583\n",
      "Epoch 222/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9805\n",
      "Epoch 00222: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0612 - accuracy: 0.9805 - val_loss: 0.0998 - val_accuracy: 0.9593\n",
      "Epoch 223/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9809\n",
      "Epoch 00223: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0608 - accuracy: 0.9809 - val_loss: 0.1017 - val_accuracy: 0.9590\n",
      "Epoch 224/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9805\n",
      "Epoch 00224: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0611 - accuracy: 0.9805 - val_loss: 0.1051 - val_accuracy: 0.9577\n",
      "Epoch 225/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9808\n",
      "Epoch 00225: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0603 - accuracy: 0.9808 - val_loss: 0.1011 - val_accuracy: 0.9603\n",
      "Epoch 226/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9809\n",
      "Epoch 00226: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0608 - accuracy: 0.9809 - val_loss: 0.0999 - val_accuracy: 0.9573\n",
      "Epoch 227/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9811\n",
      "Epoch 00227: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0606 - accuracy: 0.9811 - val_loss: 0.1018 - val_accuracy: 0.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9812\n",
      "Epoch 00228: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0605 - accuracy: 0.9812 - val_loss: 0.1004 - val_accuracy: 0.9580\n",
      "Epoch 229/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9806\n",
      "Epoch 00229: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0609 - accuracy: 0.9806 - val_loss: 0.0992 - val_accuracy: 0.9590\n",
      "Epoch 230/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9808\n",
      "Epoch 00230: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0603 - accuracy: 0.9808 - val_loss: 0.1041 - val_accuracy: 0.9577\n",
      "Epoch 231/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9807\n",
      "Epoch 00231: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0601 - accuracy: 0.9807 - val_loss: 0.1006 - val_accuracy: 0.9610\n",
      "Epoch 232/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9806\n",
      "Epoch 00232: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0602 - accuracy: 0.9806 - val_loss: 0.0997 - val_accuracy: 0.9577\n",
      "Epoch 233/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9809\n",
      "Epoch 00233: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0602 - accuracy: 0.9809 - val_loss: 0.1021 - val_accuracy: 0.9583\n",
      "Epoch 234/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9804\n",
      "Epoch 00234: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0599 - accuracy: 0.9804 - val_loss: 0.0982 - val_accuracy: 0.9597\n",
      "Epoch 235/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9812\n",
      "Epoch 00235: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0599 - accuracy: 0.9812 - val_loss: 0.1017 - val_accuracy: 0.9587\n",
      "Epoch 236/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9812\n",
      "Epoch 00236: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0598 - accuracy: 0.9812 - val_loss: 0.0992 - val_accuracy: 0.9600\n",
      "Epoch 237/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9815\n",
      "Epoch 00237: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0598 - accuracy: 0.9815 - val_loss: 0.1002 - val_accuracy: 0.9583\n",
      "Epoch 238/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9813\n",
      "Epoch 00238: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 93s 247ms/step - loss: 0.0599 - accuracy: 0.9813 - val_loss: 0.1010 - val_accuracy: 0.9580\n",
      "Epoch 239/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9808\n",
      "Epoch 00239: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0596 - accuracy: 0.9808 - val_loss: 0.0993 - val_accuracy: 0.9587\n",
      "Epoch 240/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9809\n",
      "Epoch 00240: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0596 - accuracy: 0.9809 - val_loss: 0.0994 - val_accuracy: 0.9593\n",
      "Epoch 241/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9811\n",
      "Epoch 00241: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0592 - accuracy: 0.9811 - val_loss: 0.0995 - val_accuracy: 0.9593\n",
      "Epoch 242/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9810\n",
      "Epoch 00242: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.1003 - val_accuracy: 0.9583\n",
      "Epoch 243/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9811 ETA: 1s - loss: 0.0600 - ac\n",
      "Epoch 00243: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0596 - accuracy: 0.9811 - val_loss: 0.0997 - val_accuracy: 0.9600\n",
      "Epoch 244/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9811\n",
      "Epoch 00244: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0599 - accuracy: 0.9811 - val_loss: 0.0990 - val_accuracy: 0.9590\n",
      "Epoch 245/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9819\n",
      "Epoch 00245: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0591 - accuracy: 0.9819 - val_loss: 0.1012 - val_accuracy: 0.9583\n",
      "Epoch 246/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9812\n",
      "Epoch 00246: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0593 - accuracy: 0.9812 - val_loss: 0.0997 - val_accuracy: 0.9583\n",
      "Epoch 247/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9806\n",
      "Epoch 00247: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0597 - accuracy: 0.9806 - val_loss: 0.1001 - val_accuracy: 0.9573\n",
      "Epoch 248/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9816\n",
      "Epoch 00248: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0592 - accuracy: 0.9816 - val_loss: 0.0991 - val_accuracy: 0.9580\n",
      "Epoch 249/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9817\n",
      "Epoch 00249: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0591 - accuracy: 0.9817 - val_loss: 0.0997 - val_accuracy: 0.9570\n",
      "Epoch 250/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9816\n",
      "Epoch 00250: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0588 - accuracy: 0.9816 - val_loss: 0.1003 - val_accuracy: 0.9580\n",
      "Epoch 251/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.9821\n",
      "Epoch 00251: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0589 - accuracy: 0.9821 - val_loss: 0.1019 - val_accuracy: 0.9583\n",
      "Epoch 252/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9813\n",
      "Epoch 00252: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0591 - accuracy: 0.9813 - val_loss: 0.0999 - val_accuracy: 0.9570\n",
      "Epoch 253/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9822\n",
      "Epoch 00253: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0585 - accuracy: 0.9822 - val_loss: 0.0999 - val_accuracy: 0.9573\n",
      "Epoch 254/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9812\n",
      "Epoch 00254: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0587 - accuracy: 0.9812 - val_loss: 0.1013 - val_accuracy: 0.9597\n",
      "Epoch 255/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9817\n",
      "Epoch 00255: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0587 - accuracy: 0.9817 - val_loss: 0.0998 - val_accuracy: 0.9607\n",
      "Epoch 256/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9810\n",
      "Epoch 00256: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 90s 241ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.1029 - val_accuracy: 0.9580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9815\n",
      "Epoch 00257: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0590 - accuracy: 0.9815 - val_loss: 0.1023 - val_accuracy: 0.9607\n",
      "Epoch 258/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.9817\n",
      "Epoch 00258: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 90s 241ms/step - loss: 0.0589 - accuracy: 0.9817 - val_loss: 0.0984 - val_accuracy: 0.9597\n",
      "Epoch 259/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9810\n",
      "Epoch 00259: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 241ms/step - loss: 0.0584 - accuracy: 0.9810 - val_loss: 0.1002 - val_accuracy: 0.9593\n",
      "Epoch 260/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9814\n",
      "Epoch 00260: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0582 - accuracy: 0.9814 - val_loss: 0.0996 - val_accuracy: 0.9597\n",
      "Epoch 261/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.9815\n",
      "Epoch 00261: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0589 - accuracy: 0.9815 - val_loss: 0.0996 - val_accuracy: 0.9597\n",
      "Epoch 262/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9811\n",
      "Epoch 00262: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0587 - accuracy: 0.9811 - val_loss: 0.0994 - val_accuracy: 0.9600\n",
      "Epoch 263/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9817\n",
      "Epoch 00263: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 90s 241ms/step - loss: 0.0577 - accuracy: 0.9817 - val_loss: 0.0991 - val_accuracy: 0.9593\n",
      "Epoch 264/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9826\n",
      "Epoch 00264: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0580 - accuracy: 0.9826 - val_loss: 0.1029 - val_accuracy: 0.9603\n",
      "Epoch 265/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9812\n",
      "Epoch 00265: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0583 - accuracy: 0.9812 - val_loss: 0.1015 - val_accuracy: 0.9583\n",
      "Epoch 266/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9815\n",
      "Epoch 00266: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0584 - accuracy: 0.9815 - val_loss: 0.0996 - val_accuracy: 0.9603\n",
      "Epoch 267/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9816\n",
      "Epoch 00267: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0580 - accuracy: 0.9816 - val_loss: 0.1001 - val_accuracy: 0.9573\n",
      "Epoch 268/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9819\n",
      "Epoch 00268: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0578 - accuracy: 0.9819 - val_loss: 0.1048 - val_accuracy: 0.9583\n",
      "Epoch 269/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9813\n",
      "Epoch 00269: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0583 - accuracy: 0.9813 - val_loss: 0.1005 - val_accuracy: 0.9580\n",
      "Epoch 270/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9822\n",
      "Epoch 00270: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0576 - accuracy: 0.9822 - val_loss: 0.1006 - val_accuracy: 0.9587\n",
      "Epoch 271/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9818\n",
      "Epoch 00271: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0576 - accuracy: 0.9818 - val_loss: 0.0996 - val_accuracy: 0.9577\n",
      "Epoch 272/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9824\n",
      "Epoch 00272: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0576 - accuracy: 0.9824 - val_loss: 0.0996 - val_accuracy: 0.9580\n",
      "Epoch 273/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9821\n",
      "Epoch 00273: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.0575 - accuracy: 0.9821 - val_loss: 0.0991 - val_accuracy: 0.9597\n",
      "Epoch 274/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9825\n",
      "Epoch 00274: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0579 - accuracy: 0.9825 - val_loss: 0.1011 - val_accuracy: 0.9590\n",
      "Epoch 275/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9816\n",
      "Epoch 00275: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0574 - accuracy: 0.9816 - val_loss: 0.0998 - val_accuracy: 0.9593\n",
      "Epoch 276/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9821\n",
      "Epoch 00276: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0575 - accuracy: 0.9821 - val_loss: 0.1006 - val_accuracy: 0.9587\n",
      "Epoch 277/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9815\n",
      "Epoch 00277: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0577 - accuracy: 0.9815 - val_loss: 0.0999 - val_accuracy: 0.9577\n",
      "Epoch 278/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9828\n",
      "Epoch 00278: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0572 - accuracy: 0.9828 - val_loss: 0.0983 - val_accuracy: 0.9600\n",
      "Epoch 279/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9822 ETA: 3s -\n",
      "Epoch 00279: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0576 - accuracy: 0.9822 - val_loss: 0.0999 - val_accuracy: 0.9583\n",
      "Epoch 280/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9819\n",
      "Epoch 00280: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0574 - accuracy: 0.9819 - val_loss: 0.0981 - val_accuracy: 0.9590\n",
      "Epoch 281/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9819\n",
      "Epoch 00281: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0569 - accuracy: 0.9819 - val_loss: 0.1022 - val_accuracy: 0.9607\n",
      "Epoch 282/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9816\n",
      "Epoch 00282: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0571 - accuracy: 0.9816 - val_loss: 0.0992 - val_accuracy: 0.9590\n",
      "Epoch 283/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9824\n",
      "Epoch 00283: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0570 - accuracy: 0.9824 - val_loss: 0.1067 - val_accuracy: 0.9573\n",
      "Epoch 284/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9818\n",
      "Epoch 00284: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0575 - accuracy: 0.9818 - val_loss: 0.1005 - val_accuracy: 0.9580\n",
      "Epoch 285/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9823\n",
      "Epoch 00285: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0570 - accuracy: 0.9823 - val_loss: 0.0989 - val_accuracy: 0.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9818\n",
      "Epoch 00286: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0574 - accuracy: 0.9818 - val_loss: 0.0983 - val_accuracy: 0.9593\n",
      "Epoch 287/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9825\n",
      "Epoch 00287: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0573 - accuracy: 0.9825 - val_loss: 0.0992 - val_accuracy: 0.9597\n",
      "Epoch 288/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9822\n",
      "Epoch 00288: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 244ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 0.0986 - val_accuracy: 0.9593\n",
      "Epoch 289/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9824\n",
      "Epoch 00289: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0568 - accuracy: 0.9824 - val_loss: 0.0988 - val_accuracy: 0.9597\n",
      "Epoch 290/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9825\n",
      "Epoch 00290: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0565 - accuracy: 0.9825 - val_loss: 0.0996 - val_accuracy: 0.9580\n",
      "Epoch 291/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9822\n",
      "Epoch 00291: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0563 - accuracy: 0.9822 - val_loss: 0.0987 - val_accuracy: 0.9597\n",
      "Epoch 292/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9817\n",
      "Epoch 00292: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0565 - accuracy: 0.9817 - val_loss: 0.0994 - val_accuracy: 0.9600\n",
      "Epoch 293/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9822\n",
      "Epoch 00293: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 243ms/step - loss: 0.0565 - accuracy: 0.9822 - val_loss: 0.0996 - val_accuracy: 0.9587\n",
      "Epoch 294/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9827\n",
      "Epoch 00294: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0564 - accuracy: 0.9827 - val_loss: 0.0996 - val_accuracy: 0.9580\n",
      "Epoch 295/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9822\n",
      "Epoch 00295: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0563 - accuracy: 0.9822 - val_loss: 0.1056 - val_accuracy: 0.9597\n",
      "Epoch 296/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9824\n",
      "Epoch 00296: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0565 - accuracy: 0.9824 - val_loss: 0.0992 - val_accuracy: 0.9593\n",
      "Epoch 297/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9831\n",
      "Epoch 00297: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 92s 245ms/step - loss: 0.0563 - accuracy: 0.9831 - val_loss: 0.0982 - val_accuracy: 0.9603\n",
      "Epoch 298/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9827\n",
      "Epoch 00298: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0557 - accuracy: 0.9827 - val_loss: 0.0981 - val_accuracy: 0.9593\n",
      "Epoch 299/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9821\n",
      "Epoch 00299: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0562 - accuracy: 0.9821 - val_loss: 0.0979 - val_accuracy: 0.9603\n",
      "Epoch 300/300\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9822\n",
      "Epoch 00300: val_accuracy did not improve from 0.96233\n",
      "375/375 [==============================] - 91s 244ms/step - loss: 0.0561 - accuracy: 0.9822 - val_loss: 0.0985 - val_accuracy: 0.9593\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=300, validation_split=0.2, callbacks=[lr_reduce,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('M3_E_300_ImageNet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정확도 및 손실값에 대한 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'],'b-',label = 'loss')\n",
    "plt.plot(history.history['val_loss'],'r--',label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'],'g-',label = 'accuracy')\n",
    "plt.plot(history.history['val_accuracy'],'k--',label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 23s 192ms/step - loss: 0.1552 - accuracy: 0.9445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15522964298725128, 0.9445333480834961]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최종평가\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
